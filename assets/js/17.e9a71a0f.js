(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{433:function(e,r,t){"use strict";t.r(r);var n=t(2),o=Object(n.a)({},(function(){var e=this,r=e._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey},scopedSlots:e._u([{key:"personalInfo",fn:function(){return[r("p",[e._v("I am an incoming Senior Researcher at Microsoft Research (MSR) in Vancouver, Canada.")]),e._v(" "),r("p",[e._v("I just graduated with DPhil (aka Ph.D.) in "),r("a",{attrs:{href:"http://www.cs.ox.ac.uk/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Computer Science Department"),r("OutboundLink")],1),e._v(", "),r("a",{attrs:{href:"https://www.ox.ac.uk/",target:"_blank",rel:"noopener noreferrer"}},[e._v("University of Oxford"),r("OutboundLink")],1),e._v(", and a member of "),r("a",{attrs:{href:"https://www.st-hughs.ox.ac.uk/",target:"_blank",rel:"noopener noreferrer"}},[e._v("St Hugh's"),r("OutboundLink")],1),e._v(" college,\nwhere I was co-advised by Prof. "),r("a",{attrs:{href:"https://www.cs.ox.ac.uk/people/andrew.markham/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Andrew Markham"),r("OutboundLink")],1),e._v(" and Prof. "),r("a",{attrs:{href:"https://www.cs.ox.ac.uk/people/niki.trigoni/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Niki Trigoni"),r("OutboundLink")],1),e._v(". I interned at Mitsubishi\nElectric Research Laboratories ("),r("a",{attrs:{href:"https://www.merl.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MERL"),r("OutboundLink")],1),e._v(") from  June 2023 to Dec. 2023, and Microsoft Applied Sciences Group in Munich, Germany ("),r("a",{attrs:{href:"https://www.microsoft.com",target:"_blank",rel:"noopener noreferrer"}},[e._v("Microsoft"),r("OutboundLink")],1),e._v(") from May 2024 to August 2024. I received B.Eng. from "),r("a",{attrs:{href:"https://www.whu.edu.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Wuhan University"),r("OutboundLink")],1),e._v(", China.")]),e._v(" "),r("p",[e._v("My research interest lies in Multimodal Embodied AI; Audio-visual Multimodal Learning; 3D Multimodal AR/VR; Signal Processing (Fourier/Wavelet Transform) inspired Deep Learning; Physics-informed Deep Learning, etc.")]),e._v(" "),r("p",[e._v("Drop me an email (yuhang.he[at]cs.ox.ac.uk) if you want to contact. I write blogs as part of my research notes, you are welcome to support a "),r("a",{attrs:{href:"https://www.buymeacoffee.com/yuhanghe01",target:"_blank",rel:"noopener noreferrer"}},[e._v("cup of coffee"),r("OutboundLink")],1),e._v(" if you find them\nhelpful.")])]},proxy:!0}])},[r("h1",{attrs:{id:"news"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#news"}},[e._v("#")]),e._v(" News")]),e._v(" "),r("ul",[r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"https://2025.ieeeicassp.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ICASSP 2025"),r("OutboundLink")],1),e._v(". 2024.12.")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"https://wacv2025.thecvf.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WACV 2025"),r("OutboundLink")],1),e._v(". 2024.10.")]),e._v(" "),r("li",[e._v("Serve as "),r("a",{attrs:{href:"https://aaai.org/conference/aaai/aaai-25/",target:"_blank",rel:"noopener noreferrer"}},[e._v("AAAI 2025"),r("OutboundLink")],1),e._v(" program committee, "),r("a",{attrs:{href:"https://2025.ieeeicassp.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ICASSP 2025"),r("OutboundLink")],1),e._v(" area chair. 2024.09.")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"http://neurips.cc/",target:"_blank",rel:"noopener noreferrer"}},[e._v("NeurIPS 2024"),r("OutboundLink")],1),e._v(". 2024.09.")]),e._v(" "),r("li",[e._v("One paper accepted by Nature Communications Engineering, "),r("a",{attrs:{href:"https://www.nature.com/articles/s44172-024-00220-5",target:"_blank",rel:"noopener noreferrer"}},[e._v("paper link"),r("OutboundLink")],1),e._v(".")]),e._v(" "),r("li",[e._v("Started internship at Microsoft's Applied Sciences Group (ASG) in Munich, Germany. 2024.05.")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"https://icml.cc/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ICML 2024"),r("OutboundLink")],1),e._v(". 2024.05.")]),e._v(" "),r("li",[e._v("Won student volunteer scholarship for "),r("a",{attrs:{href:"https://aaai.org/aaai-conference/",target:"_blank",rel:"noopener noreferrer"}},[e._v("AAAI 2024"),r("OutboundLink")],1),e._v(". 2023.12.")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"https://aaai.org/aaai-conference/",target:"_blank",rel:"noopener noreferrer"}},[e._v("AAAI 2024"),r("OutboundLink")],1),e._v(". 2023.12.")]),e._v(" "),r("li",[e._v("Accepted by "),r("a",{attrs:{href:"https://wacv2024.thecvf.com/doctoral-consortium/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WACV 2024 Doctoral Consortium"),r("OutboundLink")],1),e._v(". 2023.11.")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"https://wacv2024.thecvf.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WACV 2024"),r("OutboundLink")],1),e._v(". 2023.10.")]),e._v(" "),r("li",[e._v("Start internship at Mitsubishi Electric Research Laboratories "),r("a",{attrs:{href:"https://www.merl.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MERL"),r("OutboundLink")],1),e._v(". 2023.06;")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"https://roboticsconference.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Robotics: Science and Systems RSS 2023"),r("OutboundLink")],1),e._v(". 2023.04;")]),e._v(" "),r("li",[e._v("One paper accepted by "),r("a",{attrs:{href:"http://aistats.org/aistats2023/",target:"_blank",rel:"noopener noreferrer"}},[e._v("AISTATS 2023"),r("OutboundLink")],1),e._v(". 2023.01;")]),e._v(" "),r("li",[e._v("Completed confirmation viva by examiners Prof. "),r("a",{attrs:{href:"https://www.cs.ox.ac.uk/people/alex.rogers/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Alex Rogers"),r("OutboundLink")],1),e._v(" and Asso. Prof. "),r("a",{attrs:{href:"https://www.ronnieclark.co.uk/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ronald Clark"),r("OutboundLink")],1),e._v(". 2022.10;")]),e._v(" "),r("li",[e._v("Received "),r("a",{attrs:{href:"https://interspeech2022.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Interspeech 2022"),r("OutboundLink")],1),e._v(" travel grant. 2022.07;")]),e._v(" "),r("li",[e._v("Paper accepted by "),r("a",{attrs:{href:"https://interspeech2022.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Interspeech 2022"),r("OutboundLink")],1),e._v(". 2022.06;")]),e._v(" "),r("li",[e._v("Worked as ICML21 student volunteer. 2021.06;")]),e._v(" "),r("li",[e._v("Paper accepted by "),r("a",{attrs:{href:"https://icml.cc/Conferences/2021",target:"_blank",rel:"noopener noreferrer"}},[e._v("ICML2021"),r("OutboundLink")],1),e._v(". 2021.05;")]),e._v(" "),r("li",[e._v("Completed transfer viva by examiners Prof. "),r("a",{attrs:{href:"http://mnslab.org/tamvu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Tam Vu"),r("OutboundLink")],1),e._v(" and Prof. "),r("a",{attrs:{href:"https://www.cs.ox.ac.uk/people/alex.rogers/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Alex Rogers"),r("OutboundLink")],1),e._v(".  2021.01;")])]),e._v(" "),r("h1",{attrs:{id:"publications"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#publications"}},[e._v("#")]),e._v(" Publications")]),e._v(" "),r("p",[e._v("For full publication list, please refer to "),r("a",{attrs:{href:"https://scholar.google.com/citations?user=H1p3ve8AAAAJ&hl=en",target:"_blank",rel:"noopener noreferrer"}},[e._v("Google Scholar"),r("OutboundLink")],1),e._v(" or "),r("RouterLink",{attrs:{to:"/publications/"}},[e._v("â†’ Full list")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/spear_img.png",link:"https://arxiv.org/abs/2406.11006"}},[r("p",[r("strong",[e._v("SPEAR: Receiver-to-Receiver Acoustic Neural Warping Field")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", "),r("strong",[e._v("Shitong Xu")]),e._v(", Jia-Xing Zhong, Sangyun Shin, Niki Trigoni, Andrew Markham.")]),e._v(" "),r("p",[e._v("We propose a receiver-to-receiver neural spatial acoustic effects prediction for an arbitrary target position from a reference position. It requires\nneither sound source position nor room acoustic properties.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://arxiv.org/abs/2406.11006"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/spear.bib"}},[e._v("BibTex")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://github.com/xu-shitong/spear"}},[e._v("Code")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/deepnerap_icml24.png",link:"https://icml.cc/virtual/2024/poster/33608"}},[r("p",[r("strong",[e._v("Deep Neural Room Acoustics Primitive")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", Anoop Cherian, Gordon Wichern, Andrew Markham.")]),e._v(" "),r("p",[e._v("The 41st International Conference on Machine Learning (ICML), 2024.")]),e._v(" "),r("p",[e._v("We introduce a novel framework to learn a continuous neural room acoustics field that implicitly encodes all essential sound propagation primitives for each enclosed 3D space.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://proceedings.mlr.press/v235/he24b.html"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/deepnerap.bib"}},[e._v("BibTex")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://icml.cc/media/icml-2024/Slides/33608.pdf"}},[e._v("Poster")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/soundcount.png",link:"https://arxiv.org/pdf/2312.16149.pdf"}},[r("p",[r("strong",[e._v("SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", Zhuangzhuang Dai, Long Chen, Niki Trigoni, Andrew Markham.")]),e._v(" "),r("p",[e._v("The 38th Annual AAAI Conference on Artificial Intelligence (AAAI), 2024.")]),e._v(" "),r("p",[e._v("We introduce a learnable dyadic decomposition framework that learns more representative time-frequency representation from highly polyphonic and loudness\nvarying sound waveform. It dyadically decomposes the waveform in multi-stage hierarchical manner.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://arxiv.org/pdf/2312.16149.pdf"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/soundcount.bib"}},[e._v("BibTex")]),e._v(" "),r("LinkBtn",{attrs:{href:"/projects/soundcount-poster.pdf"}},[e._v("Poster")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/sound3dvdet.png",link:"https://openaccess.thecvf.com/content/WACV2024/html/He_Sound3DVDet_3D_Sound_Source_Detection_Using_Multiview_Microphone_Array_and_WACV_2024_paper.html"}},[r("p",[r("strong",[e._v("Sound3DVDet: 3D Sound Source Detection Using Multiview Microphone Array and RGB Images")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", Sangyun Shin, Anoop Cherian, Niki Trigoni, Andrew Markham.")]),e._v(" "),r("p",[e._v("IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.")]),e._v(" "),r("p",[e._v("We introduce a novel 3D sound source localization and classification from multiview acoustic-camera recordings task. The sound source\nlies on object's physical surface but visually non-observable, which reflects some application cases like gas leaking.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://openaccess.thecvf.com/content/WACV2024/papers/He_Sound3DVDet_3D_Sound_Source_Detection_Using_Multiview_Microphone_Array_and_WACV_2024_paper.pdf"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/sound3dvdet.bib"}},[e._v("BibTex")]),e._v(" "),r("LinkBtn",{attrs:{href:"/projects/sound3dvdet-poster.pdf"}},[e._v("Poster")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://github.com/yuhanghe01/Sound3DVDet"}},[e._v("Code")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/deepexplorer.png",link:"https://www.roboticsproceedings.org/rss19/p099.pdf"}},[r("p",[r("strong",[e._v("Metric-Free Exploration for Topological Mapping by Task and Motion Imitation in Feature Space")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", "),r("strong",[e._v("Irving Fang")]),e._v(", Yiming Li, Rushi Bhavesh Shah, Chen Feng.")]),e._v(" "),r("p",[e._v("Robotics: Science and Systems (RSS), 2023.")]),e._v(" "),r("p",[e._v("We propose metric-free DeepExplorer to efficiently construct topological map to represent an environment. DeepExplorers\nexhibits strong sim2sim and sim2real generalization capability.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://www.roboticsproceedings.org/rss19/p099.pdf"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/deepexplorer.bib"}},[e._v("BibTex")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://ai4ce.github.io/DeepExplorer/"}},[e._v("Project")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://github.com/ai4ce/DeepExplorer"}},[e._v("Code")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/soundsynp.png",link:"https://proceedings.mlr.press/v206/he23c/he23c.pdf"}},[r("p",[r("strong",[e._v("SoundSynp: Sound Source Detection from Raw Waveforms with Multi-Scale Synperiodic Filterbanks")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", Andrew Markham")]),e._v(" "),r("p",[e._v("International Conference on Artificial Intelligence and Statistics (AISTATS), 2023.")]),e._v(" "),r("p",[e._v("We propose a novel framework to construct learnable sound signal processing filter banks that achieve multi-scale processing in both time and frequency domain.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://proceedings.mlr.press/v206/he23c/he23c.pdf"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/SoundSynp.bib"}},[e._v("BibTex")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://github.com/yuhanghe01/SoundSynp"}},[e._v("Code")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/SoundDoA.png",link:""}},[r("p",[r("strong",[e._v("SoundDoA: Learn Sound Source Direction of Arrival and Semantics from Sound Raw Waveforms")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", Andrew Markham")]),e._v(" "),r("p",[e._v("Interspeech, 2022.")]),e._v(" "),r("p",[e._v("We propose a novel sound event direction of arrival (DoA) estimation framework with a novel filter bank to jointly learn sound event semantics and spatial location relevant representations.")]),e._v(" "),r("LinkBtn",{attrs:{href:"https://www.isca-archive.org/interspeech_2022/he22_interspeech.pdf"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/SoundDoA.bib"}},[e._v("BibTex")])],1),e._v(" "),r("PublicationCard",{attrs:{image:"/projects/SoundDet_ICML21_Thumbnail.png",link:"http://proceedings.mlr.press/v139/he21b/he21b.pdf"}},[r("p",[r("strong",[e._v("SoundDet: Polyphonic Moving Sound Event Detection and Localization from Raw Waveform")])]),e._v(" "),r("p",[r("strong",[e._v("Yuhang He")]),e._v(", Niki Trigoni, Andrew Markham")]),e._v(" "),r("p",[e._v("International Conference on Machine Learning (ICML), 2021.")]),e._v(" "),r("p",[e._v("We propose a novel sound event detection framework for polyphonic and moving sound event detection. We also propose novel object-based evaluation metrics to evaluate performance more objectively.")]),e._v(" "),r("LinkBtn",{attrs:{href:"http://proceedings.mlr.press/v139/he21b/he21b.pdf"}},[e._v("PDF")]),e._v(" "),r("LinkBtn",{attrs:{type:"dialog",href:"/publications/SoundDet.bib"}},[e._v("BibTex")])],1),e._v(" "),r("h1",{attrs:{id:"public-office-hours"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#public-office-hours"}},[e._v("#")]),e._v(" PUBLIC OFFICE HOURS")]),e._v(" "),r("p",[e._v("I am always happy to chat with people who are interested in my work. You can check the following office hour I keep update\nto book a time slot if you want to chat.")]),e._v(" "),r("OfficeHours",{attrs:{src:"https://calendly.com/yuhanghe01/30min"}})],1)}),[],!1,null,null,null);r.default=o.exports}}]);